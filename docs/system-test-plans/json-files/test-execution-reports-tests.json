[
  {
    "test_plan_no": "STP-032-01",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.1: Reports Dashboard Page",
    "description": "Verify that the test execution reports page loads correctly with proper authentication and comprehensive data display",
    "scenario": "Admin user navigates to view comprehensive test execution reports and analytics",
    "expected_results": "Display the reports page with summary statistics, module-wise results, recent executions, failed tests analysis, and export options",
    "procedure": "1. Log in as admin user\n2. Navigate to /admin/system-test/reports\n3. Verify page loads with title 'Test Execution Reports'\n4. Check comprehensive analysis subtitle is displayed\n5. Verify all main sections are present: summary statistics, module results, recent executions, failed tests, and report info",
    "test_status": "pending",
    "priority": "critical",
    "category": "functional"
  },
  {
    "test_plan_no": "STP-032-02",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.2: Authentication Security Check",
    "description": "Verify that non-admin users cannot access the test execution reports functionality",
    "scenario": "Regular user attempts to access test execution reports directly",
    "expected_results": "Access should be denied with 403 Forbidden error for non-admin users",
    "procedure": "1. Log in as regular user (non-admin)\n2. Attempt to navigate to /admin/system-test/reports\n3. Verify 403 Forbidden error is returned\n4. Check redirect to appropriate error page\n5. Ensure no reports interface is accessible",
    "test_status": "pending",
    "priority": "critical",
    "category": "security"
  },
  {
    "test_plan_no": "STP-032-03",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.3: Page Header and Navigation",
    "description": "Verify the page header displays correct title and provides proper navigation options",
    "scenario": "Admin views reports page header to understand context and access navigation options",
    "expected_results": "Display header with title, description, and navigation buttons including back to dashboard and export options",
    "procedure": "1. Navigate to reports page\n2. Check title shows 'Test Execution Reports'\n3. Verify description shows 'Comprehensive analysis of test execution results'\n4. Confirm 'Back to Dashboard' button navigates to dashboard\n5. Check export buttons are present (DOCX, JSON, Print)\n6. Verify proper styling and fade-in animation",
    "test_status": "pending",
    "priority": "medium",
    "category": "ui"
  },
  {
    "test_plan_no": "STP-032-04",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.4: Summary Statistics Cards",
    "description": "Verify the summary statistics section displays accurate test counts and percentages",
    "scenario": "Admin views overall test execution statistics for quick overview of test status",
    "expected_results": "Display four statistics cards showing total tests, passed tests, failed tests, and pending tests with accurate counts and percentages",
    "procedure": "1. Locate summary statistics section with 4 cards\n2. Verify 'Total Tests' card shows correct count with clipboard icon\n3. Check 'Passed' card shows count, pass rate percentage, and green styling\n4. Confirm 'Failed' card shows count, failure rate percentage, and red styling\n5. Verify 'Pending' card shows count with 'Awaiting execution' text and yellow styling\n6. Check all icons and colors are properly displayed",
    "test_status": "pending",
    "priority": "high",
    "category": "functional"
  },
  {
    "test_plan_no": "STP-032-05",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.5: Module-wise Test Results Section",
    "description": "Verify the module-wise results section displays comprehensive statistics for each module",
    "scenario": "Admin views detailed breakdown of test results organized by module",
    "expected_results": "Display module-wise results with test counts, pass rates, progress bars, and navigation links",
    "procedure": "1. Locate 'Module-wise Test Results' section\n2. Verify each module shows name as clickable link to module tests page\n3. Check test count is displayed for each module\n4. Confirm passed, failed, and pending counts are shown in grid layout\n5. Verify progress bar reflects pass rate with appropriate width\n6. Check pass rate percentage is displayed accurately\n7. Confirm proper styling with borders and rounded corners",
    "test_status": "pending",
    "priority": "high",
    "category": "functional"
  },
  {
    "test_plan_no": "STP-032-06",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.6: Recent Test Executions Timeline",
    "description": "Verify the recent test executions section displays tests from the last 30 days",
    "scenario": "Admin views recent test execution history to track testing activity",
    "expected_results": "Display recent test executions with test plan numbers, status badges, execution dates, and executor information",
    "procedure": "1. Locate 'Recent Test Executions' section with 'Last 30 days' subtitle\n2. Verify up to 10 recent executions are displayed\n3. Check each execution shows test plan number\n4. Confirm status badges are color-coded (green=passed, red=failed, gray=skipped)\n5. Verify module name and execution date/time are displayed\n6. Check executed_by user information is shown when available\n7. Confirm eye icon links to view test plan page",
    "test_status": "pending",
    "priority": "high",
    "category": "functional"
  },
  {
    "test_plan_no": "STP-032-07",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.7: Failed Tests Analysis Table",
    "description": "Verify the failed tests analysis section displays detailed information about failed tests",
    "scenario": "Admin reviews failed tests to identify issues requiring attention",
    "expected_results": "Display failed tests table with test plan details, failure reasons, priorities, and action buttons",
    "procedure": "1. Check if failed tests section appears when failed tests exist\n2. Verify table headers: Test Plan, Module, Failure Reason, Last Executed, Priority, Actions\n3. Check test plan numbers are clickable links to view test plan\n4. Confirm failure reasons are displayed with truncation for long text\n5. Verify execution dates are formatted correctly\n6. Check priority badges are color-coded (red=critical, orange=high, blue=medium, green=low)\n7. Confirm action buttons: view (eye), re-execute (play), edit (pencil)",
    "test_status": "pending",
    "priority": "critical",
    "category": "functional"
  },
  {
    "test_plan_no": "STP-032-08",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.8: No Data States Handling",
    "description": "Verify proper display when no test data is available",
    "scenario": "Admin views reports page when no test modules or recent executions exist",
    "expected_results": "Display appropriate messages and icons for empty data states",
    "procedure": "1. Test with empty modules summary data\n2. Verify 'No test modules found' message with inbox icon\n3. Test with no recent executions\n4. Check 'No recent test executions found' message with calendar-x icon\n5. Confirm failed tests section is hidden when no failed tests exist\n6. Verify empty states have proper styling and spacing",
    "test_status": "pending",
    "priority": "medium",
    "category": "functional"
  },
  {
    "test_plan_no": "STP-032-09",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.9: Export DOCX Functionality",
    "description": "Verify the DOCX export functionality generates proper document with all test plans",
    "scenario": "Admin exports test plans to DOCX format for documentation purposes",
    "expected_results": "Generate and download DOCX file with formatted test plans and proper document structure",
    "procedure": "1. Click 'Export DOCX' button\n2. Verify request is sent to /admin/system-test/export/docx endpoint\n3. Check file download is initiated\n4. Verify filename format includes current date\n5. Open downloaded DOCX and confirm proper formatting\n6. Check document includes title, generation date, and all test plans\n7. Verify table structure and content are properly formatted",
    "test_status": "pending",
    "priority": "high",
    "category": "functional"
  },
  {
    "test_plan_no": "STP-032-10",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.10: Export JSON Functionality",
    "description": "Verify the JSON export functionality generates proper report data",
    "scenario": "Admin exports report data to JSON format for data analysis",
    "expected_results": "Generate and download JSON file with structured report data including summary and module information",
    "procedure": "1. Click 'Export JSON' button\n2. Verify JavaScript function exportJSON() executes\n3. Check JSON structure includes generated_at timestamp\n4. Confirm summary section with test counts and pass rate\n5. Verify modules array with detailed statistics\n6. Check failed_tests array with test information\n7. Confirm file download with date-formatted filename",
    "test_status": "pending",
    "priority": "medium",
    "category": "functional"
  },
  {
    "test_plan_no": "STP-032-11",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.11: Print Report Functionality",
    "description": "Verify the print functionality provides properly formatted printable report",
    "scenario": "Admin prints report for physical documentation or archival purposes",
    "expected_results": "Open print dialog with optimized print styles and proper formatting",
    "procedure": "1. Click 'Print Report' button\n2. Verify browser print dialog opens\n3. Check print preview shows optimized layout\n4. Confirm print styles remove shadows and optimize colors\n5. Verify font sizes are appropriate for printing\n6. Check page breaks and layout are print-friendly\n7. Confirm all essential information is included in print version",
    "test_status": "pending",
    "priority": "low",
    "category": "functional"
  },
  {
    "test_plan_no": "STP-032-12",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.12: Report Generation Information",
    "description": "Verify the report generation information section displays accurate metadata",
    "scenario": "Admin views report generation details to understand data currency and scope",
    "expected_results": "Display report generation timestamp and explanatory information about data scope",
    "procedure": "1. Locate report information section with blue background\n2. Verify info icon and title 'Report Information'\n3. Check generation timestamp is displayed correctly\n4. Confirm explanation about data scope and 30-day timeframe\n5. Verify proper styling with blue theme\n6. Check text is clear and informative",
    "test_status": "pending",
    "priority": "low",
    "category": "functional"
  },
  {
    "test_plan_no": "STP-032-13",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.13: Progress Bar Visual Feedback",
    "description": "Verify module progress bars accurately represent pass rates with proper visual feedback",
    "scenario": "Admin observes progress bars to quickly assess module performance",
    "expected_results": "Progress bars show accurate widths based on pass rates with green color indication",
    "procedure": "1. Locate module progress bars in module-wise results\n2. Verify bar width corresponds to calculated pass rate percentage\n3. Check green color is used for progress indication\n4. Confirm background is gray for unfilled portion\n5. Verify rounded corners and proper height\n6. Check transition effects are smooth",
    "test_status": "pending",
    "priority": "low",
    "category": "ui"
  },
  {
    "test_plan_no": "STP-032-14",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.14: Status Badge Color Coding",
    "description": "Verify status badges use proper color coding for different test statuses",
    "scenario": "Admin identifies test statuses quickly through visual color coding",
    "expected_results": "Status badges display with appropriate colors: green for passed, red for failed, gray for skipped",
    "procedure": "1. Check passed test badges are green with 'Passed' text\n2. Verify failed test badges are red with 'Failed' text\n3. Confirm skipped test badges are gray with 'Skipped' text\n4. Check badge styling includes proper padding and rounded corners\n5. Verify text is clearly readable on colored backgrounds\n6. Test dark mode compatibility if available",
    "test_status": "pending",
    "priority": "medium",
    "category": "ui"
  },
  {
    "test_plan_no": "STP-032-15",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.15: Priority Badge Styling",
    "description": "Verify priority badges in failed tests table use appropriate color coding",
    "scenario": "Admin identifies test priorities through visual indicators in failed tests analysis",
    "expected_results": "Priority badges display with color-coded styling: red for critical, orange for high, blue for medium, green for low",
    "procedure": "1. Check critical priority badges are red\n2. Verify high priority badges are orange\n3. Confirm medium priority badges are blue\n4. Check low priority badges are green\n5. Verify badge text matches priority level\n6. Confirm proper styling with padding and rounded corners",
    "test_status": "pending",
    "priority": "medium",
    "category": "ui"
  },
  {
    "test_plan_no": "STP-032-16",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.16: Responsive Layout Adaptation",
    "description": "Verify the reports page layout adapts properly to different screen sizes",
    "scenario": "Admin accesses reports page on various devices and screen sizes",
    "expected_results": "Page layout adapts with responsive grid system maintaining readability and functionality",
    "procedure": "1. View page on desktop (1920x1080) - verify 4-column statistics and 2-column sections\n2. Test on tablet view (1024px) - check 2-column statistics adaptation\n3. Check mobile view (375px) - verify single column stacking\n4. Confirm table horizontal scrolling on narrow screens\n5. Verify all buttons and navigation remain accessible\n6. Check text remains readable at all screen sizes",
    "test_status": "pending",
    "priority": "medium",
    "category": "ui"
  },
  {
    "test_plan_no": "STP-032-17",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.17: Navigation Link Integration",
    "description": "Verify all navigation links within reports page function correctly",
    "scenario": "Admin navigates through various links to access related functionality",
    "expected_results": "All navigation links work correctly and maintain proper context",
    "procedure": "1. Click 'Back to Dashboard' button and verify navigation to dashboard\n2. Click module name links and confirm navigation to module tests page\n3. Test test plan number links in recent executions and failed tests\n4. Click action buttons (view, re-execute, edit) in failed tests table\n5. Verify all links maintain proper admin context\n6. Check hover effects and styling are consistent",
    "test_status": "pending",
    "priority": "high",
    "category": "functional"
  },
  {
    "test_plan_no": "STP-032-18",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.18: Data Accuracy and Calculations",
    "description": "Verify all calculated values and percentages are accurate based on underlying data",
    "scenario": "Admin reviews report calculations to ensure data integrity and accuracy",
    "expected_results": "All calculated values, percentages, and counts accurately reflect the underlying test data",
    "procedure": "1. Verify total test count matches sum of passed, failed, and pending\n2. Check pass rate calculation is correct (passed/total * 100)\n3. Confirm failure rate calculation is accurate\n4. Verify module statistics sum correctly\n5. Check recent executions filter correctly for 30-day period\n6. Confirm failed tests query returns only failed status tests",
    "test_status": "pending",
    "priority": "critical",
    "category": "functional"
  },
  {
    "test_plan_no": "STP-032-19",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.19: Error Handling and Recovery",
    "description": "Verify proper error handling when reports generation encounters issues",
    "scenario": "Reports page encounters various error conditions during data loading",
    "expected_results": "Display appropriate error messages and handle errors gracefully without breaking the interface",
    "procedure": "1. Simulate database connection error during reports loading\n2. Verify 500 error is returned appropriately\n3. Check error is logged on server side\n4. Test with malformed test data\n5. Verify graceful handling of missing or null values\n6. Confirm user sees appropriate error feedback",
    "test_status": "pending",
    "priority": "high",
    "category": "functional"
  },
  {
    "test_plan_no": "STP-032-20",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.20: Page Performance and Loading",
    "description": "Verify the reports page loads efficiently with good performance",
    "scenario": "Admin measures reports page performance with various amounts of test data",
    "expected_results": "Page loads within acceptable time limits and handles large datasets efficiently",
    "procedure": "1. Measure page load time with typical dataset\n2. Test performance with large number of test plans (100+)\n3. Check database query efficiency\n4. Verify fade-in animations don't impact performance\n5. Test scroll performance with long lists\n6. Confirm memory usage remains reasonable",
    "test_status": "pending",
    "priority": "medium",
    "category": "performance"
  },
  {
    "test_plan_no": "STP-032-21",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.21: Date and Time Formatting",
    "description": "Verify date and time information is displayed in consistent, readable formats",
    "scenario": "Admin views various date/time fields to ensure consistent formatting",
    "expected_results": "All dates and times display in consistent, user-friendly formats",
    "procedure": "1. Check report generation timestamp format (Month DD, YYYY at HH:MM)\n2. Verify execution dates in recent executions (MM/DD/YYYY HH:MM AM/PM)\n3. Confirm last executed dates in failed tests table (MM/DD/YYYY)\n4. Check timezone handling for execution dates\n5. Verify date formatting is consistent across all sections\n6. Test edge cases like missing dates",
    "test_status": "pending",
    "priority": "low",
    "category": "functional"
  },
  {
    "test_plan_no": "STP-032-22",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.22: Text Truncation and Tooltips",
    "description": "Verify long text content is properly truncated with tooltips for full content",
    "scenario": "Admin views reports with long failure reasons and test descriptions",
    "expected_results": "Long text is truncated with ellipsis and full content available on hover",
    "procedure": "1. Test failure reason display with long text content\n2. Verify text is truncated with ellipsis (...)\n3. Check title attribute shows full content on hover\n4. Confirm max-width constraints are applied\n5. Test with various text lengths\n6. Verify tooltip functionality works across browsers",
    "test_status": "pending",
    "priority": "low",
    "category": "ui"
  },
  {
    "test_plan_no": "STP-032-23",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.23: Dark Mode Compatibility",
    "description": "Verify the reports page displays correctly in dark mode theme",
    "scenario": "Admin switches to dark mode to ensure proper theme support",
    "expected_results": "All page elements adapt to dark theme with appropriate colors and contrast",
    "procedure": "1. Enable dark mode theme\n2. Verify background colors adapt (gray-900 for main, gray-800 for cards)\n3. Check text colors provide sufficient contrast\n4. Confirm borders and shadows adapt to dark theme\n5. Verify status and priority badges remain readable\n6. Check export buttons maintain proper styling",
    "test_status": "pending",
    "priority": "medium",
    "category": "ui"
  },
  {
    "test_plan_no": "STP-032-24",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.24: Accessibility Compliance",
    "description": "Verify the reports page meets accessibility standards for screen readers and keyboard navigation",
    "scenario": "Admin and accessibility tools test page for compliance with accessibility standards",
    "expected_results": "Page is fully accessible via keyboard navigation and screen readers",
    "procedure": "1. Navigate entire page using only keyboard (Tab, Enter)\n2. Test with screen reader for proper content reading\n3. Verify focus indicators are visible on interactive elements\n4. Check proper heading hierarchy (h1, h3, h4)\n5. Confirm tables have proper headers and structure\n6. Verify buttons and links have descriptive text or aria-labels",
    "test_status": "pending",
    "priority": "medium",
    "category": "ui"
  },
  {
    "test_plan_no": "STP-032-25",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.25: Browser Compatibility Testing",
    "description": "Verify reports functionality works across different web browsers",
    "scenario": "Admin accesses reports using various browsers to ensure cross-browser compatibility",
    "expected_results": "Reports display and function correctly in Chrome, Firefox, Safari, and Edge",
    "procedure": "1. Test reports page in Google Chrome (latest version)\n2. Verify functionality in Mozilla Firefox\n3. Check display and features in Safari (if available)\n4. Test in Microsoft Edge browser\n5. Confirm JavaScript export functions work in each browser\n6. Verify print functionality across browsers",
    "test_status": "pending",
    "priority": "medium",
    "category": "functional"
  },
  {
    "test_plan_no": "STP-032-26",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.26: Table Overflow and Scrolling",
    "description": "Verify failed tests table handles overflow content with proper scrolling",
    "scenario": "Admin views failed tests table with many entries or on narrow screens",
    "expected_results": "Table provides horizontal scrolling when needed and maintains proper layout",
    "procedure": "1. Test table with many failed tests entries\n2. Verify horizontal scrolling appears when needed\n3. Check table headers remain visible during scroll\n4. Confirm all columns remain accessible\n5. Test on narrow screen sizes\n6. Verify table maintains proper styling during overflow",
    "test_status": "pending",
    "priority": "low",
    "category": "ui"
  },
  {
    "test_plan_no": "STP-032-27",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.27: Icon Display and Styling",
    "description": "Verify all icons display correctly with proper sizing and alignment",
    "scenario": "Admin observes various icons throughout the reports interface",
    "expected_results": "All icons display with consistent sizing, proper alignment, and appropriate colors",
    "procedure": "1. Check statistics card icons (clipboard-data, check-circle, x-circle, clock)\n2. Verify navigation button icons (arrow-left, file-earmark-word, download, printer)\n3. Confirm action icons in failed tests table (eye, play-circle, pencil)\n4. Check info icon in report information section\n5. Verify icon colors match their contexts\n6. Confirm icons scale properly on different screen sizes",
    "test_status": "pending",
    "priority": "low",
    "category": "ui"
  },
  {
    "test_plan_no": "STP-032-28",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.28: Data Refresh and Currency",
    "description": "Verify reports data reflects current state of test plans and executions",
    "scenario": "Admin views reports after test executions to ensure data currency",
    "expected_results": "Reports data is current and reflects latest test execution states",
    "procedure": "1. Execute a test plan and change its status\n2. Navigate to reports page\n3. Verify updated status is reflected in statistics\n4. Check module-wise results show updated counts\n5. Confirm recent executions include new execution\n6. Verify failed tests analysis updates appropriately",
    "test_status": "pending",
    "priority": "high",
    "category": "functional"
  },
  {
    "test_plan_no": "STP-032-29",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.29: Integration with Test Management Workflow",
    "description": "Verify reports page integrates seamlessly with overall test management workflow",
    "scenario": "Admin uses reports as part of comprehensive test management activities",
    "expected_results": "Reports provide seamless integration with dashboard, test execution, and test management functions",
    "procedure": "1. Navigate to reports from dashboard\n2. Use reports to identify failed tests\n3. Navigate to individual test plans from reports\n4. Execute tests from failed tests analysis\n5. Return to reports to verify updates\n6. Export reports for external use\n7. Confirm smooth workflow integration throughout",
    "test_status": "pending",
    "priority": "high",
    "category": "integration"
  },
  {
    "test_plan_no": "STP-032-30",
    "module_name": "Test-Execution-Reports",
    "screen_design_ref": "Figure 32.30: Complete Reports Analytics Workflow",
    "description": "Verify complete test execution reports and analytics workflow from access through data export",
    "scenario": "Admin completes comprehensive reports review including analysis, navigation, and export functions",
    "expected_results": "Complete reports workflow provides comprehensive test execution analytics with actionable insights and export capabilities",
    "procedure": "1. Navigate to reports from admin dashboard\n2. Review summary statistics for overall test health\n3. Analyze module-wise results to identify problem areas\n4. Review recent test execution trends\n5. Investigate failed tests requiring attention\n6. Navigate to specific test plans for detailed review\n7. Use action buttons to re-execute or edit failed tests\n8. Export reports in DOCX format for documentation\n9. Export JSON data for further analysis\n10. Print reports for physical archival\n11. Verify all data is accurate and current\n12. Confirm seamless integration with test management workflow and proper tracking of all analytics data",
    "test_status": "pending",
    "priority": "critical",
    "category": "integration"
  }
]